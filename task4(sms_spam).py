# -*- coding: utf-8 -*-
"""Task4(sms_spam).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WlJYnL4ICZQDbgt7NJAZt_JeKx8IHF8q

#Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix
from sklearn.naive_bayes import MultinomialNB

sd = pd.read_csv('smsd.csv')
sd
sd.info()
sd.describe()
sd.head()

sd = sd.drop(columns=sd.columns[2:5])
sd.head()

sd.columns = ['Category', 'Message']
sd

sd.isnull().sum()

category_counts = sd['Category'].value_counts().reset_index()
category_counts.columns = ['Category', 'Count']
plt.figure(figsize=(8, 6))
sns.barplot(x='Category', y='Count', sd=category_counts)
plt.xlabel('Category')
plt.ylabel('Count')
plt.title('Category Distribution')

for i, count in enumerate(category_counts['Count']):
    plt.text(i, count, str(count), ha='center', va='bottom')
plt.show()

sd['spam']= sd['Category'].apply(lambda x: 1 if x=='spam' else 0)
sd

"""#Spliting Data"""

X_train, X_test, y_train, y_test = train_test_split(sd.Message,sd.spam, test_size=0.2)
from sklearn.feature_extraction.text import CountVectorizer
featurer = CountVectorizer()
X_train_count = featurer.fit_transform(X_train.values)

X_train_count

model = MultinomialNB()
model.fit(X_train_count,y_train)

X_test_count = featurer.transform(X_test)
model.score(X_test_count, y_test)

from sklearn.pipeline import Pipeline
clf = Pipeline([
    ('vectorizer', CountVectorizer()),
    ('nb', MultinomialNB())
])

clf.fit(X_train, y_train)

clf.score(X_test,y_test)

"""#Pre_Trained_Model"""

# Pre-trained model
pretrained_model = model
new_sentences = [
    "Your account have 100 debeted, is waiting to be collected. Simply text the password \MIX\" to 85069 to verify. Get Usher and Britney. FML"
]

new_sentences_count = featurer.transform(new_sentences)
# Predict whether each sentence is spam (1) or not (0)
predictions = pretrained_model.predict(new_sentences_count)

for sentence, prediction in zip(new_sentences, predictions):
    if prediction == 1:
        print(f"'{sentence}' is a spam message.")
    else:
        print(f"'{sentence}' is not a spam message.")